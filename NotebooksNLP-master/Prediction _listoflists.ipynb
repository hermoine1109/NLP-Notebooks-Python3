{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of token list: 2053640\n",
      "Length of unique token list: 73682\n",
      "Enter your test string: She was the\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-56d3a854a814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrigramSet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrigrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "f=open('Data/LanguageModels/corpusfile.txt','r')\n",
    "content=f.read()\n",
    "token=content.split()\n",
    "#token=nltk.word_tokenize(\"I like playing football in the rain with my shoes on in the rain, without, my, shoes on in the rain with my jacket on because it helps to refresh my mind and make my dull brain fresh\")\n",
    "#print (token)\n",
    "tokenList=list(token)\n",
    "\n",
    "print (\"Length of token list: \"+ str(len(token)))\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "#print (len(stop))\n",
    "unigrams=list(ngrams(token,1))\n",
    "bigrams=list(ngrams(token,2))\n",
    "trigrams=list(ngrams(token,3))\n",
    "quadgrams=list(ngrams(token,4))\n",
    "trigramSet=set(trigrams)\n",
    "quadgramSet=set(quadgrams)\n",
    "\n",
    "#Preprocessing the input text\n",
    "\n",
    "i=0\n",
    "for word1 in tokenList:\n",
    "    tokenList[i]=word1.lower()\n",
    "    #Takes Care of Multiple Punctuation Marks\n",
    "    tokenList[i]=word1.replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','')      \n",
    "    i=i+1\n",
    "\n",
    "tokenSet=set(tokenList) \n",
    "print (\"Length of unique token list: \"+ str(len(tokenSet)))\n",
    "#print (tokenSet)\n",
    "#print (trigramSet)\n",
    "#print (\"Length of the bigram list is %d\" %(len(bigrams)))\n",
    "#print (\"Length of the trigram list is %d\" %(len(trigrams)))\n",
    "#print (\"Type of each bigram entry is %s\" %(type(bigrams[0])))\n",
    "#print (\"Length of the trigram list is %d\" %(len(quadgrams)))i\n",
    "\n",
    "nonstop=set()\n",
    "for item in tokenSet:\n",
    "    if item not in stop:\n",
    "        nonstop.add(item)\n",
    "        \n",
    "#print (nonstop)\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "#Finding probability of \"I like playing\"\n",
    "\n",
    "test=input(\"Enter your test string: \")\n",
    "token2=nltk.word_tokenize(test)\n",
    "#print (token2)\n",
    "unigrams2=list(ngrams(token2,1))\n",
    "#print (str(unigrams2[0]))\n",
    "bigrams2=list(ngrams(token2,2))\n",
    "trigrams2=list(ngrams(token2,3))\n",
    "quadgrams2=list(ngrams(token2,4))\n",
    "#print (token2.count(unigrams2[1]))\n",
    "#unigram probability\n",
    "#print (\"In unigram model Probability of sentence = %f\" %(token2.count(unigrams2[0])* token2.count(unigrams[1])* token2.count(unigrams[2])/float(len(token)*len(token)*len(token))))\n",
    "\n",
    "\n",
    "#table for trigrams and their probabilities\n",
    "n=len(trigramSet)\n",
    "table=[[0 for i in range(2)] for i in range(n)]\n",
    "i=0\n",
    "\n",
    "for item in trigramSet:\n",
    "    item=' '.join(item)\n",
    "    if(i<n):\n",
    "        table[i][0]=item\n",
    "    i+=1\n",
    "for item in trigramSet:\n",
    "    for token in trigrams:\n",
    "        key=' '.join(token)\n",
    "        if(item==token):\n",
    "            for i in range(n):\n",
    "                if(table[i][0]==key):\n",
    "                    table[i][1]+=1\n",
    "                    \n",
    "#print (table)\n",
    "\n",
    "#table for quadgrams and their probabilities\n",
    "\n",
    "n2=len(quadgramSet)\n",
    "table2=[[0 for i in range(2)] for i in range(n2)]\n",
    "i=0\n",
    "\n",
    "for item in quadgramSet:\n",
    "    item=' '.join(item)\n",
    "    if(i<n2):\n",
    "        table2[i][0]=item\n",
    "    i+=1\n",
    "for item in quadgramSet:\n",
    "    for token in quadgrams:\n",
    "        key=' '.join(token)\n",
    "        if(item==token):\n",
    "            for i in range(n2):\n",
    "                if(table2[i][0]==key):\n",
    "                    table2[i][1]+=1\n",
    "                    \n",
    "#print (table2)\n",
    "max_freq=0\n",
    "index=i\n",
    "\n",
    "%timeit\n",
    "\n",
    "for item in tokenSet:\n",
    "    predict= test+' '+item\n",
    "    #print (predict)\n",
    "    for i in range(n2):\n",
    "        if(predict==table2[i][0]):\n",
    "            freq=table2[i][1]\n",
    "            if(freq>max_freq):\n",
    "                max_freq=freq\n",
    "                index=i\n",
    "                \n",
    "print (table2[index][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of token list: 1013\n",
      "Length of unique token list: 344\n",
      "Length of the trigram list is 1011\n",
      "Enter your test string: I wrote this\n",
      "['I', 'wrote', 'this']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2a6ee34ba745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtestlist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdquad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "f=open('Data/Tokenization/Chat1.txt','r')\n",
    "content=f.read()\n",
    "token=content.split()\n",
    "#token=nltk.word_tokenize(\"I like playing football in the rain with my shoes on in the rain without my shoes on in the rain with my jacket on because it helps to refresh my mind and make my dull brain fresh\")\n",
    "#print (token)\n",
    "tokenList=list(token)\n",
    "tokenSet=set(tokenList)\n",
    "print (\"Length of token list: \"+ str(len(token)))\n",
    "print (\"Length of unique token list: \"+ str(len(tokenSet)))\n",
    "unigrams=list(ngrams(token,1))\n",
    "bigrams=list(ngrams(token,2))\n",
    "trigrams=list(ngrams(token,3))\n",
    "quadgrams=list(ngrams(token,4))\n",
    "trigramSet=set(trigrams)\n",
    "quadgramSet=set(quadgrams)\n",
    "#print (trigramSet)\n",
    "\n",
    "\n",
    "\n",
    "#print (\"Length of the bigram list is %d\" %(len(bigrams)))\n",
    "print (\"Length of the trigram list is %d\" %(len(trigrams)))\n",
    "#print (\"Type of each bigram entry is %s\" %(type(bigrams[0])))\n",
    "#print (\"Length of the trigram list is %d\" %(len(quadgrams)))\n",
    "\n",
    "#Finding probability of \"I like playing\"\n",
    "\n",
    "test=input(\"Enter your test string: \")\n",
    "token2=nltk.word_tokenize(test)\n",
    "#print (token2)\n",
    "unigrams2=list(ngrams(token2,1))\n",
    "#print (str(unigrams2[0]))\n",
    "bigrams2=list(ngrams(token2,2))\n",
    "trigrams2=list(ngrams(token2,3))\n",
    "quadgrams2=list(ngrams(token2,4))\n",
    "#print (token2.count(unigrams2[1]))\n",
    "#unigram probability\n",
    "#print (\"In unigram model Probability of sentence = %f\" %(token2.count(unigrams2[0])* token2.count(unigrams[1])* token2.count(unigrams[2])/float(len(token)*len(token)*len(token))))\n",
    "fileobj = open(\"freq.txt\", \"w\")\n",
    "  \n",
    "for item in unigrams:\n",
    "    fileobj.write(str(item))\n",
    "    fileobj.write('\\t')\n",
    "    fileobj.write(str(token.count(item)))\n",
    "    fileobj.write('\\n')\n",
    "    \n",
    "fileobj.close()\n",
    "\n",
    "#dictionary for trigrams and their probabilities\n",
    "dtri={}\n",
    "dtri=dict.fromkeys(trigramSet,0)\n",
    "\n",
    "for item in trigrams:\n",
    "    for key,value in dtri.items():\n",
    "        if(key==item):\n",
    "            dtri[key]=dtri[key]+1\n",
    "\n",
    "\n",
    "\n",
    "#dictionary for quadgrams and their probabilities\n",
    "\n",
    "dquad={}\n",
    "dquad=dict.fromkeys(quadgramSet,0)\n",
    "#print (d)\n",
    "\n",
    "#n=len(trigramSet)\n",
    "#table=[[0 for i in range(2)] for i in range(n)]\n",
    "#i=0\n",
    "\n",
    "\n",
    "\n",
    "for item in quadgrams:\n",
    "    for key,value in dquad.items():\n",
    "        if(key==item):\n",
    "            dquad[key]=dquad[key]+1\n",
    "                    \n",
    "\n",
    "\n",
    "max_freq=0\n",
    "freq=0\n",
    "prediction=''\n",
    "testtokens=nltk.word_tokenize(test)\n",
    "testlist=list(testtokens)\n",
    "print (testlist)\n",
    "\n",
    "\n",
    "                    \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
