{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compounds and Compounding </h2>\n",
    "\n",
    "Compounding is a productive process of vocabulary expansion in languages where two or more nouns are used together to generate a new lexeme. Compound analysis is computationally challenging primarily due to three factors:\n",
    "<br>\n",
    "<br>\n",
    "i). Compounds are highly productive in nature<br>\n",
    "ii). The relation between the components is implicit and<br>\n",
    "iii). The correct interpretation of a compound is often dependent on contextual or pragmatic features .<br>\n",
    "\n",
    "For example, ‘houseboat’ and ‘boathouse’ are compounds formed from the same pair of nouns, ‘house’ and ‘boat’, but do not mean the same. Similarly, the relation between ‘olive’ and ‘oil’ in ‘olive oil’ does not hold between ‘baby’ and ‘oil’ in ‘baby oil’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compounds in Sanskrit </h2>\n",
    "\n",
    "The compounds in Sanskrit exhibit numerous regularities that characterise them. Compounds in Sanskrit are concatenative in nature, with a strict preference for the ordering of the components.\n",
    "A generated compound is treated as a fully qualified word (pada), such that the compound is subject to\n",
    "all the inflectional and derivational modifications applicable to nouns. Affixation occurs at the end of the\n",
    "compound similar to languages like that of Greek and not within the components. Any compound can be analysed by decomposing it into two immediate component nouns.\n",
    "Linguists in Sanskrit have deeply discussed exceptions for the aforementioned regularities leading\n",
    "to different categorisations and further sub-categorisations of the compound types . We only consider the four broad categorisations of the compounds. We now explain four classes of compounds and discuss various discriminative aspects about the broad level classes that we can abstract out from the generated forms and use in our system. In Sanskrit Grammar, compounds are classified into four general categories, namely, Avyayı̄bhāva, Tatpurus.a, Bahuvrı̄hi and Dvandva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dataset Description </h2>\n",
    "\n",
    "A labelled dataset of compounds and the decomposed pairs of components. The dataset contains more than 32000 unique compounds. The compounds were obtained from ancient digitised texts including Śrı̄mad Bhagavat Gı̄ta, Caraka sam\n",
    ". hitā among others.\n",
    "\n",
    "The dataset contains the sandhi split components along with the compounds. With more than 75 % of the dataset containing Tatpurus.a compounds, we down-sample the Tatpurus.a compounds to a count of 4000, to match with the second highest class, Bahuvrı̄hi. We find that the Avyayı̄bhāva compounds are severely under-represented in the data-set, with about 5 % of the Bahuvrı̄hi class. From the dataset, we filtered <b>9952</b> different data-points split into <b>7957</b> data points for training and the remaining as held out dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Original Dataset without features</h4>\n",
    "\n",
    "Below we can see the first 10 rows of the dataset to get an idea of how it looks without additional features. The data contains word1, word2 which are the components of compounds in Sanskrit. Also dataset contains label containing the class it belongs to and which we have to predict for the heldout dataset, namely : \n",
    "- Avyayı̄bhāva (A) \n",
    "- Tatpurus.a (T)\n",
    "- Bahuvrı̄hi (B) \n",
    "- Dvandva (D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",word1,word2,label\r\n",
      "0,svAxu,paxArWAn,T\r\n",
      "1,xvAxaSa,varRANi,T\r\n",
      "2,AxAna,xurbale,T\r\n",
      "3,go,BakwAH,T\r\n",
      "4,viXi,Bexena,T\r\n",
      "5,nIwi,kuSalaM,T\r\n",
      "6,lafkA,upamam,B\r\n",
      "7,yaSas,lipsoH,T\r\n",
      "8,kaSa,AGAwam,T\r\n"
     ]
    }
   ],
   "source": [
    "!head -10 Data/EssentialsofML/trainingFiltered.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Packages needed to be imported</h3><pre>\n",
    "1.scikit-learn\n",
    "2.numpy</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Installing scikit-learn and numpy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment to install\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install -U numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Enumurating unigrams, bigrams and trigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 unigams for word1 :  )\t3\tA\tC\tB\tE\tD\tG\tF\tI\n",
      "10 bigams  for word1 :  iP\tgu\tgr\tgq\tgy\tgg\tge\tga\ttI\tgo\n",
      "10 trigams for word1 :  nwu\tnwv\tAGI\tnwy\tyay\tnwa\tbXa\tnwi\tgnI\tnwr\n",
      "10 unigams for word2 :  !\t7\t?\tA\tC\tB\tE\tD\tG\tF\n",
      "10 bigams  for word2 :  gv\tgu\tgr\tgq\ttU\tgy\ttO\tge\tga\ttI\n",
      "10 trigams for word2 :  nwu\taGo\tOkR\tnwr\tnun\tbXu\tnwy\tAGA\tbXi\tnwe\n"
     ]
    }
   ],
   "source": [
    "file = open(\"Data/EssentialsofML/trainingFiltered.csv\")\n",
    "file.readline()\n",
    "\n",
    "#get unigrams list of word\n",
    "def getUnigrams(word):\n",
    "    return list(word) \n",
    "\n",
    "#get bigrams list of word\n",
    "def getBigrams(word):\n",
    "    return [ word[i]+word[i+1] for i in range(0,len(word)-1)]\n",
    "\n",
    "#get trigrams list of word\n",
    "def getTigrams(word):\n",
    "    return [ word[i]+word[i+1]+word[i+2] for i in range(0,len(word)-2)]\n",
    "\n",
    "#read columns word1, word2 and labels\n",
    "word1Vec = []\n",
    "word2Vec = []\n",
    "labelVec = []\n",
    "\n",
    "for line in file.readlines():\n",
    "    splited_line = line.split(',')\n",
    "    word1Vec.append(splited_line[1])\n",
    "    word2Vec.append(splited_line[2])\n",
    "    labelVec.append(splited_line[3].strip())\n",
    "    \n",
    "#enumurate unigrams, bigrams and trigrams for columns word1 and word2\n",
    "unigramWord1 = reduce(lambda a,b: list(set(a+b)),map(getUnigrams,word1Vec))\n",
    "bigramWord1 = reduce(lambda a,b: list(set(a+b)),map(getBigrams,word1Vec))\n",
    "trigramWord1 = reduce(lambda a,b: list(set(a+b)),map(getTigrams,word1Vec))\n",
    "\n",
    "unigramWord2 = reduce(lambda a,b: list(set(a+b)),map(getUnigrams,word2Vec))\n",
    "bigramWord2 = reduce(lambda a,b: list(set(a+b)),map(getBigrams,word2Vec))\n",
    "trigramWord2 = reduce(lambda a,b: list(set(a+b)),map(getTigrams,word2Vec))\n",
    "\n",
    "print \"10 unigams for word1 : \",\"\\t\".join(unigramWord1[:10])\n",
    "print \"10 bigams  for word1 : \",\"\\t\".join(bigramWord1[:10])\n",
    "print \"10 trigams for word1 : \",\"\\t\".join(trigramWord1[:10])\n",
    "print \"10 unigams for word2 : \",\"\\t\".join(unigramWord2[:10])\n",
    "print \"10 bigams  for word2 : \",\"\\t\".join(bigramWord2[:10])\n",
    "print \"10 trigams for word2 : \",\"\\t\".join(trigramWord2[:10])\n",
    "    \n",
    "#combining ngrmas for word1 and word2\n",
    "featureVecForWord1 = unigramWord1+bigramWord1+trigramWord1\n",
    "featureVecForWord2 = unigramWord2+bigramWord2+trigramWord2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Calculating Entropy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10  features for word1 :  wrA\tuRp\tdga\taws\tadg\tsI\tnwu\tnim\tviB\tvim\n",
      "Worst 10 features for word1 :  p\tv\tu\ts\ti\tn\tw\tA\tr\ta\n",
      "Best 10  features for word2 :  Axe\tyaj\tRya\tvip\tlin\tSar\tAsi\tval\tame\taNe\n",
      "Worst 10 features for word2 :  k\ty\ti\tH\tn\tw\tr\tm\tA\ta\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#count of all feactures over column word1, word2 \n",
    "countNgramsWord1 = [ sum([ word1.count(ngram) for word1 in word1Vec ]) for ngram in featureVecForWord1]\n",
    "countNgramsWord2 = [ sum([ word2.count(ngram) for word2 in word2Vec ]) for ngram in featureVecForWord2]\n",
    "\n",
    "#for each class constructing a vector of counts of occurances for each feature\n",
    "aCountWord1 = [ sum([ word1Vec[i].count(ngram) for i in range(len(word1Vec)) if labelVec[i]=='A' ]) for ngram in featureVecForWord1 ]\n",
    "kCountWord1 = [ sum([ word1Vec[i].count(ngram) for i in range(len(word1Vec)) if labelVec[i]=='K' ]) for ngram in featureVecForWord1 ]\n",
    "bCountWord1 = [ sum([ word1Vec[i].count(ngram) for i in range(len(word1Vec)) if labelVec[i]=='B' ]) for ngram in featureVecForWord1 ]\n",
    "tCountWord1 = [ sum([ word1Vec[i].count(ngram) for i in range(len(word1Vec)) if labelVec[i]=='T' ]) for ngram in featureVecForWord1 ]\n",
    "dCountWord1 = [ sum([ word1Vec[i].count(ngram) for i in range(len(word1Vec)) if labelVec[i]=='D' ]) for ngram in featureVecForWord1 ]\n",
    "\n",
    "aCountWord2 = [ sum([ word2Vec[i].count(ngram) for i in range(len(word2Vec)) if labelVec[i]=='A' ]) for ngram in featureVecForWord2 ]\n",
    "kCountWord2 = [ sum([ word2Vec[i].count(ngram) for i in range(len(word2Vec)) if labelVec[i]=='K' ]) for ngram in featureVecForWord2 ]\n",
    "bCountWord2 = [ sum([ word2Vec[i].count(ngram) for i in range(len(word2Vec)) if labelVec[i]=='B' ]) for ngram in featureVecForWord2 ]\n",
    "tCountWord2 = [ sum([ word2Vec[i].count(ngram) for i in range(len(word2Vec)) if labelVec[i]=='T' ]) for ngram in featureVecForWord2 ]\n",
    "dCountWord2 = [ sum([ word2Vec[i].count(ngram) for i in range(len(word2Vec)) if labelVec[i]=='D' ]) for ngram in featureVecForWord2 ]\n",
    "\n",
    "def entropy(x):\n",
    "    return -(x*math.log(x))\n",
    "\n",
    "def get_prob_vec(tagCountWordx,countNgramsWordx,featureVecForWordx):\n",
    "    return [ (tagCountWordx[i]+1)/(float(countNgramsWordx[i])+len(featureVecForWordx)) for i in range(len(tagCountWordx)) ]\n",
    "\n",
    "#calculating probabilities and applying p(x)*log(p(x))\n",
    "aCountWord1 = map(entropy, get_prob_vec(aCountWord1, countNgramsWord1, featureVecForWord1))\n",
    "kCountWord1 = map(entropy, get_prob_vec(kCountWord1, countNgramsWord1, featureVecForWord1))\n",
    "bCountWord1 = map(entropy, get_prob_vec(bCountWord1, countNgramsWord1, featureVecForWord1))\n",
    "tCountWord1 = map(entropy, get_prob_vec(tCountWord1, countNgramsWord1, featureVecForWord1))\n",
    "dCountWord1 = map(entropy, get_prob_vec(dCountWord1, countNgramsWord1, featureVecForWord1))\n",
    "\n",
    "aCountWord2 = map(entropy, get_prob_vec(aCountWord2, countNgramsWord2, featureVecForWord2))\n",
    "kCountWord2 = map(entropy, get_prob_vec(kCountWord2, countNgramsWord2, featureVecForWord2))\n",
    "bCountWord2 = map(entropy, get_prob_vec(bCountWord2, countNgramsWord2, featureVecForWord2))\n",
    "tCountWord2 = map(entropy, get_prob_vec(tCountWord2, countNgramsWord2, featureVecForWord2))\n",
    "dCountWord2 = map(entropy, get_prob_vec(dCountWord2, countNgramsWord2, featureVecForWord2))\n",
    "\n",
    "#calculating entropy for each feature\n",
    "ngramEntropyWord1 = [ aCountWord1[i] + kCountWord1[i] + bCountWord1[i] + tCountWord1[i] + dCountWord1[i] for i in range(len(featureVecForWord1))]\n",
    "ngramEntropyWord2 = [ aCountWord2[i] + kCountWord2[i] + bCountWord2[i] + tCountWord2[i] + dCountWord2[i] for i in range(len(featureVecForWord2))]\n",
    "\n",
    "#taking top 1000 features for both word1 and word2\n",
    "topIndices1 = sorted(range(len(ngramEntropyWord1)), key=lambda i: ngramEntropyWord1[i])[-1000:]\n",
    "topIndices2 = sorted(range(len(ngramEntropyWord2)), key=lambda i: ngramEntropyWord2[i])[-1000:]\n",
    "\n",
    "#list containing best 1000 features for word1 and word2\n",
    "colfor1 = [featureVecForWord1[i] for i in topIndices1]\n",
    "colfor2 = [featureVecForWord2[i] for i in topIndices2]\n",
    "\n",
    "print 'Best 10  features for word1 : ',\"\\t\".join(colfor1[:10])\n",
    "print 'Worst 10 features for word1 : ',\"\\t\".join(colfor1[-10:])\n",
    "print 'Best 10  features for word2 : ',\"\\t\".join(colfor2[:10])\n",
    "print 'Worst 10 features for word2 : ',\"\\t\".join(colfor2[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generating files with new features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_features(inFileName,outFileName):\n",
    "    word1Vec = []\n",
    "    word2Vec = []\n",
    "    remainingCols = []\n",
    "\n",
    "    file = open(inFileName)\n",
    "    outFile = open(outFileName,\"w\")\n",
    "\n",
    "    outFile.write(file.readline().strip('\\n')[1:]+','+','.join(colfor1)+','+','.join(colfor2)+\"\\n\")\n",
    "\n",
    "    for line in file.readlines():\n",
    "        splited_line = line.split(',')\n",
    "        word1Vec.append(splited_line[1])\n",
    "        word2Vec.append(splited_line[2])\n",
    "        remainingCols.append(','.join(splited_line[3:]).split('\\n')[0])\n",
    "\n",
    "    ngramCountWord1 = [[ word1.count(ngram) for ngram in colfor1 ] for word1 in word1Vec ]\n",
    "    ngramCountWord2 = [[ word2.count(ngram) for ngram in colfor2 ] for word2 in word2Vec ]\n",
    "\n",
    "    for i in range(len(word1Vec)):\n",
    "        outFile.write(str(word1Vec[i])+','+str(word2Vec[i])+','+str(remainingCols[i])+','+','.join(map(str,ngramCountWord1[i]))+','+','.join(map(str,ngramCountWord2[i]))+\"\\n\")\n",
    "\n",
    "    outFile.close()\n",
    "    \n",
    "calculate_features(\"Data/EssentialsofML/trainingFiltered.csv\",\"Data/EssentialsofML/trainingFilteredWithNewFeatures.csv\")\n",
    "calculate_features(\"Data/EssentialsofML/heldoutFiltered.csv\",\"Data/EssentialsofML/heldoutFilteredWithNewFeatures.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reading training and heldout data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import csv\n",
    "\n",
    "reader=csv.reader(open(\"Data/EssentialsofML/trainingFilteredWithNewFeatures.csv\",\"rb\"),delimiter=',')\n",
    "result=numpy.matrix(list(reader))[1:]\n",
    "\n",
    "X = result[:,3:].astype('int')\n",
    "y = numpy.squeeze(numpy.asarray(result[:,2]))\n",
    "\n",
    "readerHeldout=csv.reader(open(\"Data/EssentialsofML/heldoutFilteredWithNewFeatures.csv\",\"rb\"),delimiter=',')\n",
    "resultHeldout=numpy.matrix(list(readerHeldout))[1:]\n",
    "\n",
    "heldoutX = resultHeldout[:,3:].astype('int')\n",
    "heldouty = numpy.squeeze(numpy.asarray(resultHeldout[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cross Validation: </h3>\n",
    "\n",
    "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting.   \n",
    "To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set.\n",
    "\n",
    "There is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can “leak” into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called “validation set”: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
    "However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\n",
    "\n",
    "A solution to this problem is a procedure called <b>cross-validation (CV for short)</b>.\n",
    "A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k “folds”:\n",
    "\n",
    "A model is trained using k-1 of the folds as training data;\n",
    "the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as it is the case when fixing an arbitrary test set), which is a major advantage in problem such as inverse inference where the number of samples is very small.\n",
    "<br>\n",
    "\n",
    "Below, we have incorporated cross validation technique on training data for all the algorithms and found the accuracy range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Support vector machines (SVMs) </h3>\n",
    "\n",
    "SVMs are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "The advantages of support vector machines are:<pre>\n",
    "1.Effective in high dimensional spaces.\n",
    "2.Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "3.Uses a subset of training points in the decision function (called support vectors), so it is also memory     efficient.\n",
    "4.Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.</pre>\n",
    "\n",
    "The disadvantages of support vector machines include:<pre>\n",
    "1.If the number of features is much greater than the number of samples, the method is likely to give poor performances.\n",
    "2.SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation.</pre>\n",
    "\n",
    "<h5>Class required to implement support vector machines </h5><br>\n",
    "class sklearn.svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=None)\n",
    "\n",
    "To read more, follow : http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation for SVM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#create model\n",
    "clf = svm.SVC(kernel=\"linear\",max_iter=-1)\n",
    "'''\n",
    "max_iter involves hard limit on iterations within solver, no limit means -1.\n",
    "\n",
    "Using linear kernel instead of RBF or radial kernel gives better accuracy.\n",
    "'''\n",
    "#Evaluate a score by cross-validation\n",
    "scores = cross_val_score(clf, X, y, cv=2)\n",
    "\n",
    "#report accuracy\n",
    "print(\"Accuracy for SVM: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>SVM on heldout data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.59      0.56      0.57        54\n",
      "          B       0.79      0.81      0.80       860\n",
      "          D       0.65      0.60      0.62       228\n",
      "          T       0.75      0.75      0.75       853\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1995\n",
      "\n",
      "Accuracy=  0.751378446115\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#create model\n",
    "clf = svm.SVC(kernel=\"linear\",max_iter=-1)\n",
    "\n",
    "#fit the model according to the training data.\n",
    "clf.fit(X, y)\n",
    "\n",
    "#predict labels for heldout data\n",
    "predictedy = clf.predict(heldoutX)\n",
    "\n",
    "#print precision recall table\n",
    "print(classification_report(heldouty, predictedy))\n",
    "\n",
    "#report accuracy on heldout data\n",
    "print \"Accuracy= \",clf.score(heldoutX, heldouty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.Random forest classifier.</h3>\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default).\n",
    "\n",
    "<h5>Class required to implement random forest classifier</h5><br>\n",
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "To read more, follow : http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation for Random Forest Classifier</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Classifier: 0.75 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#create model\n",
    "clf3 = RandomForestClassifier(n_estimators=90,min_samples_split=1,max_features='sqrt')\n",
    "'''\n",
    "increasing n_estimators increases accuracy as we are seeing more number of trees in the forest\n",
    "\n",
    "min_samples_split or minimum number of samples required to split an internal node, when set to 1, leads to increased accuracy\n",
    "\n",
    "max_features include number of features to consider when looking for the best split\n",
    "'''\n",
    "#Evaluate a score by cross-validation\n",
    "scores3 = cross_val_score(clf3, X, y, cv=10)\n",
    "\n",
    "#report accuracy\n",
    "print(\"Accuracy for Random Forest Classifier: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Random forest classifier on heldout data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.92      0.43      0.58        54\n",
      "          B       0.79      0.79      0.79       860\n",
      "          D       0.91      0.47      0.62       228\n",
      "          T       0.71      0.82      0.76       853\n",
      "\n",
      "avg / total       0.77      0.76      0.75      1995\n",
      "\n",
      "Accuracy=  0.757393483709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#create model\n",
    "clf = RandomForestClassifier(n_estimators=90,min_samples_split=1,max_features='sqrt')\n",
    "\n",
    "#fit the model according to the training data.\n",
    "clf.fit(X, y)\n",
    "\n",
    "#predict labels for heldout data\n",
    "predictedy = clf.predict(heldoutX)\n",
    "\n",
    "#print precision recall table\n",
    "print(classification_report(heldouty, predictedy))\n",
    "\n",
    "#report accuracy on heldout data\n",
    "print \"Accuracy= \",clf.score(heldoutX, heldouty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Logistic Regression (aka logit, MaxEnt) classifier</h3>\n",
    "\n",
    "In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the ‘multi_class’ option is set to ‘ovr’, and uses the cross- entropy loss if the ‘multi_class’ option is set to ‘multinomial’. (Currently the ‘multinomial’ option is supported only by the ‘lbfgs’, ‘sag’ and ‘newton-cg’ solvers.)\n",
    "\n",
    "This class implements regularized logistic regression using the ‘liblinear’ library, ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).\n",
    "\n",
    "The ‘newton-cg’, ‘sag’, and ‘lbfgs’ solvers support only L2 regularization with primal formulation. The ‘liblinear’ solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty.\n",
    "\n",
    "<h5>Class required to implement Logistic Regression (aka logit, MaxEnt) classifier</h5><br>\n",
    "class sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "\n",
    "To read more, follow : http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation for Logistic Regression</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#create model\n",
    "clf2 = LogisticRegressionCV(solver='liblinear')\n",
    "'''\n",
    "solver is the algorithm to use in the optimization problem and liblinear gives good accuracy.\n",
    "'''\n",
    "#Evaluate a score by cross-validation\n",
    "scores2 = cross_val_score(clf2, X, y, cv=3)\n",
    "\n",
    "#report accuracy\n",
    "print(\"Accuracy for Logistic Regression: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logistic Regression Classifier on heldout data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       1.00      0.39      0.56        54\n",
      "          B       0.80      0.81      0.80       860\n",
      "          D       0.69      0.52      0.59       228\n",
      "          T       0.73      0.80      0.77       853\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1995\n",
      "\n",
      "Accuracy=  0.760902255639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#create model\n",
    "clf =  LogisticRegressionCV(solver='liblinear')\n",
    "\n",
    "#fit the model according to the training data.\n",
    "clf.fit(X, y)\n",
    "\n",
    "#predict labels for heldout data\n",
    "predictedy = clf.predict(heldoutX)\n",
    "\n",
    "#print precision recall table\n",
    "print(classification_report(heldouty, predictedy))\n",
    "\n",
    "#report accuracy on heldout data\n",
    "print \"Accuracy= \",clf.score(heldoutX, heldouty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Decision trees </h3>\n",
    "\n",
    "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "<h5>Class required to implement Decision trees </h5><br>\n",
    "class sklearn.tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_split=1e-07, class_weight=None, presort=False)\n",
    "\n",
    "To read more, follow : http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation for Decision Tree Classifier</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#create model\n",
    "clf1 = tree.DecisionTreeClassifier(splitter='random',max_features='sqrt')\n",
    "'''\n",
    "to get the best random split we use splitter as random\n",
    "\n",
    "max_features include the number of features to consider when looking for the best split and on sqrt we get good accuracy.\n",
    "default : None\n",
    "\n",
    "'''\n",
    "\n",
    "#Evaluate a score by cross-validation\n",
    "scores1 = cross_val_score(clf1, X, y, cv=10)\n",
    "\n",
    "#report accuracy\n",
    "print(\"Accuracy for Decision Tree Classifier: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Decision Tree Classifier on heldout data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#create model\n",
    "clf = tree.DecisionTreeClassifier(splitter='random',max_features='sqrt')\n",
    "\n",
    "#fit the model according to the training data.\n",
    "clf.fit(X, y)\n",
    "\n",
    "#predict labels for heldout data\n",
    "predictedy = clf.predict(heldoutX)\n",
    "\n",
    "#print precision recall table\n",
    "print(classification_report(heldouty, predictedy))\n",
    "\n",
    "#report accuracy on heldout data\n",
    "print \"Accuracy= \",clf.score(heldoutX, heldouty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparison between the above implemented algorithms</h3><br>\n",
    "<table>\n",
    "<tr>\n",
    "<td><b>Classification Algorithm</b></td>\n",
    "<td><b>Accuracy</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>SVM with RBF kernel</td>\n",
    "<td>0.60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>SVM with linear kernel</td>\n",
    "<td>0.75</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Random Forest</td>\n",
    "<td>0.76</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Logistic Regression</td>\n",
    "<td>0.76</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Decision Tree</td>\n",
    "<td>0.65</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>References</h2>\n",
    "- Scikit Learn : http://scikit-learn.org\n",
    "- Numpy : http://www.numpy.org/\n",
    "- Krishna, Amrith, Satuluri, Pavankumar, Sharma, Shubham, Kumar, Apurv and Goyal, Pawan (2016). Compound Type Identiﬁcation in Sanskrit: What Roles do the Corpus and Grammar Play?. WSSANLP, Workshop at Coling 2016, Osaka, Japan, December 11-16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Developers</h2>\n",
    "<ul>\n",
    "<li>Bhargavkumar Patel <a href=\"mailto:bhargav079@gmail.com\">bhargav079@gmail.com</a><br></li>\n",
    "<li>Minesh Gandhi <a href=\"mailto:mineshmini33@gmail.com\">mineshmini33@gmail.com</a><br></li>\n",
    "<li>Prachi Agarwal <a href=\"mailto:24prachiagarwal@gmail.com\">24prachiagarwal@gmail.com</a></li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
