{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(tokenList):\n",
    "    i=0\n",
    "    for word1 in tokenList:\n",
    "    #conversion into lowercase\n",
    "        word1=word1.lower()\n",
    "    #Takes Care of Multiple Punctuation Marks\n",
    "        word1=word1.replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','').replace('-','').replace('_','').replace('\\\\',' ').replace('\\\"',' ').replace('\\'',' ')      \n",
    "    \n",
    "        tokenList[i]=word1        \n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating unigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unigramize(unigrams):\n",
    "    \n",
    "    od=Counter()\n",
    "    \n",
    "    for item in unigrams:\n",
    "        od[item]+=1\n",
    "        \n",
    "    return od"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating bigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigramize(bigrams):\n",
    "    od2=Counter()\n",
    "\n",
    "\n",
    "    for item in bigrams:\n",
    "        od2[item]+=1\n",
    "        \n",
    "    return od2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating trigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigramize(trigrams):\n",
    "    od3=Counter()\n",
    "\n",
    "\n",
    "    for item in trigrams:\n",
    "        od3[item]+=1\n",
    "        \n",
    "    return od3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating quadgram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quadgramize(quadgrams):\n",
    "    od4=Counter()\n",
    "\n",
    "    for item in quadgrams:\n",
    "        od4[item]+=1\n",
    "        \n",
    "    return od4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uni_prob(token,unigrams):\n",
    "    \n",
    "    uni_freq=Counter(unigrams)\n",
    "    n=len(token)\n",
    "    \n",
    "    for item in uni_freq:\n",
    "        uni_freq[item]=uni_freq[item]/n\n",
    "        \n",
    "    return uni_freq\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bi_prob(unigrams,bigrams):\n",
    "    \n",
    "    uni_freq=Counter(unigrams)\n",
    "    bi_freq=Counter(bigrams)\n",
    "    \n",
    "    for item in bi_freq:\n",
    "        uni=item[0]\n",
    "        bi_freq[item]=bi_freq[item]/uni_freq[uni]\n",
    "        \n",
    "    return bi_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tri_prob(bigrams,trigrams):\n",
    "    \n",
    "    bi_freq=Counter(bigrams)\n",
    "    tri_freq=Counter(trigrams)\n",
    "    \n",
    "    for item in tri_freq:\n",
    "        bi=item[0:2]\n",
    "        tri_freq[item]=bi_freq[item]/bi_freq[bi]\n",
    "        \n",
    "    return tri_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating quadgram probability table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quad_prob(trigrams,quadgrams):\n",
    "    \n",
    "    tri_freq=Counter(trigrams)\n",
    "    quad_freq=Counter(quadgrams)\n",
    "    #print (tri_freq.items())\n",
    "    \n",
    "    for item in quad_freq:\n",
    "        tri=item[0:3]\n",
    "        quad_freq[item]=(quad_freq[item]/tri_freq[tri])\n",
    "        \n",
    "    return quad_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_table(quad_prob_table):\n",
    "    quad_pred_table=defaultdict(dict)\n",
    "    \n",
    "    for quad in quad_prob_table:\n",
    "        prob=quad_prob_table[quad]\n",
    "        tri=quad[0:3]\n",
    "        token=quad[3]\n",
    "        quad_pred_table[tri][token]=prob\n",
    "        \n",
    "    for tri in quad_pred_table:\n",
    "        quad_pred_table[tri]=sorted(quad_pred_table[tri].items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return quad_pred_table\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolation_table(od,od2,od3,od4):\n",
    "    \n",
    "    pole=defaultdict(dict)\n",
    "    \n",
    "    i=0\n",
    "    s=0.0\n",
    "    lambda1=0.25\n",
    "    lambda2=0.25\n",
    "    lambda3=0.25\n",
    "    lambda4=0.25\n",
    "    \n",
    "    for item,value in od4.items():\n",
    "        #if i>100:\n",
    "         #   break    \n",
    "        p=lambda1*float((value)/od3[item[0:3]]) + lambda2*float((od3[item[1:4]])/(od2[item[1:3]])) + lambda3*float((od2[item[2:4]])/(od[item[2]]+1)) +lambda4*(float((od[item[3]]+1)))\n",
    "        pole[item[0:3]][item[3]]=p    \n",
    "        \n",
    "    for tri in pole:\n",
    "        pole[tri]=sorted(pole[tri].items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    return pole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoreCalc(quad,tri,tokenList2):\n",
    "    score=0\n",
    "    scorepred=OrderedDict()\n",
    "    scorepred=OrderedDict.fromkeys(tokenList2,0)\n",
    "\n",
    "    for item in quad:\n",
    "        if item[0:3] in tri:\n",
    "            scorepred[item[3]]+=1\n",
    "        v=list(scorepred.values())\n",
    "        k=list(scorepred.keys())\n",
    "        if (k[v.index(max(v))]==item[3]):\n",
    "            score+=1\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add 1 Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trismooth1(tokens,tri,trigramSet2,smooth_tri):\n",
    "    \n",
    "    #Add 1 Smoothing for trigram model\n",
    "    \n",
    "    i=len(trigramSet2)\n",
    "    \n",
    "    for item in trigramSet2:\n",
    "        #smooth_bi.append(bi.count(item) + 1/float((token.count(item[0])+ len(bigramSet2))))\n",
    "        smooth_tri[item]=tri.count(item) + 1/float((tokens.count(item[0:2])+ i))\n",
    "        #print (\"%s ->  %f\" %(item,counting[i]/float((tokens.count(item[0])+ len(bigramSet2)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quadsmooth1(tokens,quad,quadgramSet2,smooth_quad):\n",
    "    \n",
    "    #Add 1 Smoothing for quadgram model\n",
    "    \n",
    "    i=len(quadgramSet2)\n",
    "    \n",
    "    for item in quadgramSet2:\n",
    "        smooth_quad[item]=quad.count(item) + 1/float((tokens.count(item[0:3])+ i))\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add k smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trismoothk(tokens,tri,trigramSet2,smooth_tri,k):\n",
    "    \n",
    "    #Add k Smoothing for trigram model\n",
    "    \n",
    "    i=len(trigramSet2)\n",
    "    \n",
    "    for item in trigramSet2:\n",
    "        smooth_tri[item]=tri.count(item) + k/float((tokens.count(item[0:2])+ i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quadsmoothk(tokens,quad,quadgramSet2,smooth_quad,k):\n",
    "    \n",
    "    #Add k Smoothing for quadgram model\n",
    "    \n",
    "    i=len(quadgramSet2)\n",
    "    \n",
    "    for item in quadgramSet2:\n",
    "        smooth_quad[item]=quad.count(item) + k/float((tokens.count(item[0:3])+ i))\n",
    "          \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quadperp(tokenList2,smooth_quad,smooth_tri,quadgramSet2):\n",
    "    \n",
    "    #computing quadgram perplexity\n",
    "    n= len (tokenList2)\n",
    "    perplexity4=1.0\n",
    "    \n",
    "    for item in quadgramSet2:\n",
    "        perplexity4=perplexity4*(((1/float(smooth_quad[item]))*smooth_tri[item[0:3]])**(1./n))\n",
    "        \n",
    "    print (\"Quadgram Perplexity = %f\" %(perplexity4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function calling all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    f=open('Data/LanguageModels/training_corpus.txt','r',encoding='latin1')\n",
    "    content=f.read()\n",
    "    token=content.split()\n",
    "\n",
    "    #splitting into tokens\n",
    "    tokenList=list(token)\n",
    "    tokenSet=set(tokenList)\n",
    "\n",
    "    #storing stop words separately\n",
    "    stop = set(stopwords.words('english'))\n",
    "    #print (len(stop))\n",
    "    #tokenSet=tokenSet-stop\n",
    "\n",
    "\n",
    "    #listing the tokens into n-grams\n",
    "    unigrams=list(ngrams(token,1))\n",
    "    bigrams=list(ngrams(token,2))\n",
    "    trigrams=list(ngrams(token,3))\n",
    "    quadgrams=list(ngrams(token,4))\n",
    "    \n",
    "    #Preprocessing the training set\n",
    "    preprocess(tokenList)\n",
    "    \n",
    "    od=Counter()\n",
    "    od=unigramize(unigrams)\n",
    "    \n",
    "    od2=Counter()\n",
    "    od2=bigramize(bigrams)\n",
    "    \n",
    "    od3=Counter()\n",
    "    od3=trigramize(trigrams)\n",
    "    \n",
    "    \n",
    "    od4=Counter()\n",
    "    od4=quadgramize(quadgrams)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Taking our input string\n",
    "    sent=input(\"Enter your test string: \")\n",
    "    list2=sent.split()\n",
    "    #test=' '.join(list2[(len(list2)-3):len(list2)])\n",
    "    sent_tri=list(ngrams(list2,3))\n",
    "    x=len(sent_tri)\n",
    "    test_tri=sent_tri[x-1]\n",
    "\n",
    "    #Normal prediction of the most probable word\n",
    "    quad_prob_table=Counter(od4)\n",
    "    quad_prob_table=quad_prob(od3,od4)\n",
    "    \n",
    "    quad_pred_table=defaultdict(dict)\n",
    "    quad_pred_table=pred_table(quad_prob_table)\n",
    "    \n",
    "    word=quad_pred_table[test_tri]\n",
    "    word=sorted(word.items(), key=lambda x: x[1], reverse=True)\n",
    "    print (\"The next word could be: \")    \n",
    "    print (word[0][0])\n",
    "    \n",
    "    #Prediction of the word after interpolation\n",
    "    quad_pole_table=defaultdict(dict)\n",
    "    quad_pole_table=interpolation_table(od,od2,od3,od4)\n",
    "    word=quad_pole_table[test_tri]\n",
    "    word=sorted(word, key=lambda x: x[1], reverse=True)\n",
    "    print (\"After interpolation, the most probable word could be: \")\n",
    "    print (word[0][0])\n",
    "    \n",
    "    #computing score of the language model\n",
    "    score=0\n",
    "    with open('Data/LanguageModels/testing_corpus.txt','r',encoding='latin1') as f:\n",
    "            contents=f.read()\n",
    "            tokens=contents.split()\n",
    "            tokenList2=list(tokens)\n",
    "     \n",
    "    #Preprocessing the test set\n",
    "    preprocess(tokens)\n",
    "    \n",
    "    bi=list(ngrams(tokenList2,2))\n",
    "    tri=list(ngrams(tokenList2,3))\n",
    "    quad=list(ngrams(tokenList2,4))\n",
    "    \n",
    "    bigramSet2=set(bi)\n",
    "    trigramSet2=set(tri)\n",
    "    quadgramSet2=set(quad)\n",
    "    \n",
    "    #print (\"Score of the language model is: \")\n",
    "    #print (scoreCalc(quad,tri,tokenList2))\n",
    "    \n",
    "    smooth_tri=OrderedDict()\n",
    "    smooth_tri=OrderedDict.fromkeys(trigramSet2,0)\n",
    "    #trismooth1(tokens,tri,trigramSet2,smooth_tri)\n",
    "    smooth_quad=OrderedDict()\n",
    "    smooth_quad=OrderedDict.fromkeys(quadgramSet2,0)\n",
    "    #quadsmooth1(tokens,quad,quadgramSet2,smooth_quad)\n",
    "    k=int(input(\"We will perform Add k smoothing now. Enter value of k: \"))\n",
    "    time1=time.time()\n",
    "    \n",
    "    trismoothk(tokens,tri,trigramSet2,smooth_tri,k)\n",
    "    quadsmoothk(tokens,quad,quadgramSet2,smooth_quad,k)\n",
    "    \n",
    "    \n",
    "    quadperp(tokenList2,smooth_quad,smooth_tri,quadgramSet2)\n",
    "    print (\"Time taken: \", time.time()-time1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your test string: I will not\n",
      "The next word could be: \n",
      "plague\n",
      "After interpolation, the most probable word could be: \n",
      "say\n",
      "We will perform Add k smoothing now. Enter value of k: 4\n",
      "Quadgram Perplexity = 1.052211\n",
      "Time taken:  34.63732933998108\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
