{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(tokenList):\n",
    "    i=0\n",
    "    for word1 in tokenList:\n",
    "    #conversion into lowercase\n",
    "        word1=word1.lower()\n",
    "    #Takes Care of Multiple Punctuation Marks\n",
    "        word1=word1.replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','').replace('-','').replace('_','').replace('\\\\',' ').replace('\\\"',' ').replace('\\'',' ')      \n",
    "    \n",
    "        tokenList[i]=word1        \n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating unigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unigramize(unigrams):\n",
    "    \n",
    "    od=Counter()\n",
    "    \n",
    "    for item in unigrams:\n",
    "        od[item]+=1\n",
    "        \n",
    "    return od"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating bigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigramize(bigrams):\n",
    "    od2=Counter()\n",
    "\n",
    "\n",
    "    for item in bigrams:\n",
    "        od2[item]+=1\n",
    "        \n",
    "    return od2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating trigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigramize(trigrams):\n",
    "    od3=Counter()\n",
    "\n",
    "\n",
    "    for item in trigrams:\n",
    "        od3[item]+=1\n",
    "        \n",
    "    return od3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating quadgram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quadgramize(quadgrams):\n",
    "    od4=Counter()\n",
    "\n",
    "    for item in quadgrams:\n",
    "        od4[item]+=1\n",
    "        \n",
    "    return od4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uni_prob(token,unigrams):\n",
    "    \n",
    "    uni_freq=Counter(unigrams)\n",
    "    n=len(token)\n",
    "    \n",
    "    for item in uni_freq:\n",
    "        uni_freq[item]=uni_freq[item]/n\n",
    "        \n",
    "    return uni_freq\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bi_prob(unigrams,bigrams):\n",
    "    \n",
    "    uni_freq=Counter(unigrams)\n",
    "    bi_freq=Counter(bigrams)\n",
    "    \n",
    "    for item in bi_freq:\n",
    "        uni=item[0]\n",
    "        bi_freq[item]=bi_freq[item]/uni_freq[uni]\n",
    "        \n",
    "    return bi_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tri_prob(bigrams,trigrams):\n",
    "    \n",
    "    bi_freq=Counter(bigrams)\n",
    "    tri_freq=Counter(trigrams)\n",
    "    \n",
    "    for item in tri_freq:\n",
    "        bi=item[0:2]\n",
    "        tri_freq[item]=bi_freq[item]/bi_freq[bi]\n",
    "        \n",
    "    return tri_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating quadgram probability table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quad_prob(trigrams,quadgrams):\n",
    "    \n",
    "    tri_freq=Counter(trigrams)\n",
    "    quad_freq=Counter(quadgrams)\n",
    "    #print (tri_freq.items())\n",
    "    \n",
    "    for item in quad_freq:\n",
    "        tri=item[0:3]\n",
    "        quad_freq[item]=(quad_freq[item]/tri_freq[tri])\n",
    "        \n",
    "    return quad_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_table(quad_prob_table):\n",
    "    quad_pred_table=defaultdict(dict)\n",
    "    \n",
    "    for quad in quad_prob_table:\n",
    "        prob=quad_prob_table[quad]\n",
    "        tri=quad[0:3]\n",
    "        token=quad[3]\n",
    "        quad_pred_table[tri][token]=prob\n",
    "        \n",
    "    for tri in quad_pred_table:\n",
    "        quad_pred_table[tri]=sorted(quad_pred_table[tri].items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return quad_pred_table\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolation_table(od,od2,od3,od4):\n",
    "    \n",
    "    pole=defaultdict(dict)\n",
    "    \n",
    "    i=0\n",
    "    s=0.0\n",
    "    lambda1=0.25\n",
    "    lambda2=0.25\n",
    "    lambda3=0.25\n",
    "    lambda4=0.25\n",
    "    \n",
    "    for item,value in od4.items():\n",
    "        #if i>100:\n",
    "         #   break    \n",
    "        p=lambda1*float((value)/od3[item[0:3]]) + lambda2*float((od3[item[1:4]])/(od2[item[1:3]])) + lambda3*float((od2[item[2:4]])/(od[item[2]]+1)) +lambda4*(float((od[item[3]]+1)))\n",
    "        pole[item[0:3]][item[3]]=p    \n",
    "        \n",
    "    for tri in pole:\n",
    "        pole[tri]=sorted(pole[tri].items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    return pole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoreCalc(quad,tri,tokenList2):\n",
    "    score=0\n",
    "    scorepred=OrderedDict()\n",
    "    scorepred=OrderedDict.fromkeys(tokenList2,0)\n",
    "\n",
    "    for item in quad:\n",
    "        if item[0:3] in tri:\n",
    "            scorepred[item[3]]+=1\n",
    "        v=list(scorepred.values())\n",
    "        k=list(scorepred.keys())\n",
    "        if (k[v.index(max(v))]==item[3]):\n",
    "            score+=1\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add k smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trismoothk(tokens,tri,trigramSet2,smooth_tri,k):\n",
    "    \n",
    "    #Add k Smoothing for trigram model\n",
    "    \n",
    "    i=len(trigramSet2)\n",
    "    \n",
    "    for item in trigramSet2:\n",
    "        smooth_tri[item]=tri.count(item) + k/float((tokens.count(item[0:2])+ i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quadsmoothk(tokens,quad,quadgramSet2,smooth_quad,k):\n",
    "    \n",
    "    #Add k Smoothing for quadgram model\n",
    "    \n",
    "    i=len(quadgramSet2)\n",
    "    \n",
    "    for item in quadgramSet2:\n",
    "        smooth_quad[item]=quad.count(item) + k/float((tokens.count(item[0:3])+ i))\n",
    "          \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Turing Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def goodturing(quadgramSet2,wcount):\n",
    "    \n",
    "    n1=0\n",
    "    n2=0\n",
    "    n=len(quadgramSet2)\n",
    "    \n",
    "    wprob=defaultdict(dict)\n",
    "    \n",
    "    \n",
    "    for item in wcount:\n",
    "        if(wcount[item]==1):\n",
    "            n1=n1+1\n",
    "        if(wcount[item]==2):\n",
    "            n2=n2+1\n",
    "    \n",
    "    for item in quadgramSet2:\n",
    "        if (wcount[item[3]]==0):\n",
    "            wcount[item[3]]=float(n1/n)\n",
    "        if (wcount[item[3]]==1):\n",
    "            wcount[item[3]]=(2*float(n2/n1))/n\n",
    "        else:\n",
    "            wcount[item[3]]=wcount[item[3]]/n\n",
    "        tri=item[0:3]\n",
    "        prob=wcount[item[3]]\n",
    "        wprob[tri][item[3]]=prob\n",
    "        \n",
    "    for tri in wprob:\n",
    "        wprob[tri]=sorted(wprob[tri].items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "            \n",
    "    return wprob\n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser Ney Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kney(od3,od4):\n",
    "    \n",
    "    kneser=defaultdict(dict)\n",
    "    d=0.25\n",
    "    lambda1=0.75\n",
    "    n1=0\n",
    "    n2=0\n",
    "    \n",
    "    for item,val1 in od4.items():\n",
    "        disc=float((od4[item]-d)/od3[item[0:3]])\n",
    "        #for tri,val2 in od3.items():\n",
    "         #   if (tri[2]==item[3]):\n",
    "        n1=od3[item[0:3]]\n",
    "        n2=od4[item]\n",
    "        cont=float(lambda1*n1/n2)\n",
    "        prob=disc+cont\n",
    "        kneser[item[0:3]][item[3]]=prob\n",
    "        \n",
    "    for tri in kneser:\n",
    "        kneser[tri]=sorted(kneser[tri].items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    return kneser\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quadperp(tokenList2,smooth_quad,smooth_tri,quadgramSet2):\n",
    "    \n",
    "    #computing quadgram perplexity\n",
    "    n= len (tokenList2)\n",
    "    perplexity4=1.0\n",
    "    \n",
    "    for item in quadgramSet2:\n",
    "        perplexity4=perplexity4*(((1/float(smooth_quad[item]))*smooth_tri[item[0:3]])**(1./n))\n",
    "        \n",
    "    print (\"Quadgram Perplexity = %f\" %(perplexity4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function calling all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    f=open('Data/LanguageModels/training_corpus.txt','r',encoding='latin1')\n",
    "    content=f.read()\n",
    "    token=content.split()\n",
    "\n",
    "    #splitting into tokens\n",
    "    tokenList=list(token)\n",
    "    tokenSet=set(tokenList)\n",
    "\n",
    "    #storing stop words separately\n",
    "    stop = set(stopwords.words('english'))\n",
    "    #print (len(stop))\n",
    "    #tokenSet=tokenSet-stop\n",
    "\n",
    "\n",
    "    #listing the tokens into n-grams\n",
    "    unigrams=list(ngrams(token,1))\n",
    "    bigrams=list(ngrams(token,2))\n",
    "    trigrams=list(ngrams(token,3))\n",
    "    quadgrams=list(ngrams(token,4))\n",
    "    \n",
    "    #Preprocessing the training set\n",
    "    preprocess(tokenList)\n",
    "    \n",
    "    od=Counter()\n",
    "    od=unigramize(unigrams)\n",
    "    \n",
    "    od2=Counter()\n",
    "    od2=bigramize(bigrams)\n",
    "    \n",
    "    od3=Counter()\n",
    "    od3=trigramize(trigrams)\n",
    "    \n",
    "    \n",
    "    od4=Counter()\n",
    "    od4=quadgramize(quadgrams)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Taking our input string\n",
    "    sent=input(\"Enter your test string: \")\n",
    "    list2=sent.split()\n",
    "    #test=' '.join(list2[(len(list2)-3):len(list2)])\n",
    "    sent_tri=list(ngrams(list2,3))\n",
    "    x=len(sent_tri)\n",
    "    test_tri=sent_tri[x-1]\n",
    "\n",
    "    #Normal prediction of the most probable word\n",
    "    time1=time.time()\n",
    "    quad_prob_table=Counter(od4)\n",
    "    quad_prob_table=quad_prob(od3,od4)\n",
    "    quad_pred_table=defaultdict(dict)\n",
    "    quad_pred_table=pred_table(quad_prob_table)\n",
    "    word=quad_pred_table[test_tri]\n",
    "    word=sorted(word.items(), key=lambda x: x[1], reverse=True)\n",
    "    print (\"The next word could be: \")    \n",
    "    print (word[0][0])\n",
    "    print (\"Time taken for prediction: \", time.time()-time1)\n",
    "    \n",
    "    #Prediction of the word after interpolation\n",
    "    time1=time.time()\n",
    "    quad_pole_table=defaultdict(dict)\n",
    "    quad_pole_table=interpolation_table(od,od2,od3,od4)\n",
    "    word=quad_pole_table[test_tri]\n",
    "    word=sorted(word, key=lambda x: x[1], reverse=True)\n",
    "    print (\"After interpolation, the most probable word could be: \")\n",
    "    print (word[0][0])\n",
    "    print (\"Time taken for prediction: \", time.time()-time1)\n",
    "    \n",
    "    #computing score of the language model\n",
    "    score=0\n",
    "    with open('Data/LanguageModels/testing_corpus.txt','r',encoding='latin1') as f:\n",
    "            contents=f.read()\n",
    "            tokens=contents.split()\n",
    "            tokenList2=list(tokens)\n",
    "     \n",
    "    #Preprocessing the test set\n",
    "    preprocess(tokens)\n",
    "    \n",
    "    bi=list(ngrams(tokenList2,2))\n",
    "    tri=list(ngrams(tokenList2,3))\n",
    "    quad=list(ngrams(tokenList2,4))\n",
    "    \n",
    "    bigramSet2=set(bi)\n",
    "    trigramSet2=set(tri)\n",
    "    quadgramSet2=set(quad)\n",
    "    \n",
    "    #Calculating Score of the language model\n",
    "    time1=time.time()\n",
    "    print (\"Score of the language model is: \")\n",
    "    print (scoreCalc(quad,tri,tokenList2))\n",
    "    print (\"Time taken for calculating Score: \", time.time()-time1)\n",
    "    \n",
    "    \n",
    "    #Add K Smoothing\n",
    "    smooth_tri=OrderedDict()\n",
    "    smooth_tri=OrderedDict.fromkeys(trigramSet2,0)\n",
    "    smooth_quad=OrderedDict()\n",
    "    smooth_quad=OrderedDict.fromkeys(quadgramSet2,0)\n",
    "    k=int(input(\"We will perform Add k smoothing now. Enter value of k: \"))\n",
    "    time1=time.time()\n",
    "    trismoothk(tokens,tri,trigramSet2,smooth_tri,k)\n",
    "    quadsmoothk(tokens,quad,quadgramSet2,smooth_quad,k)\n",
    "    print (\"Time taken for Add k Smoothing: \", time.time()-time1)\n",
    "    \n",
    "    #Good Turing Smoothing\n",
    "    od=unigramize(tokens) \n",
    "    wprob=defaultdict(dict)\n",
    "    time1=time.time()\n",
    "    wprob=goodturing(quadgramSet2,od)\n",
    "    word=wprob[test_tri]\n",
    "    word=sorted(word, key=lambda x: x[1], reverse=True)\n",
    "    print (\"After Good Turing Smoothing, the most probable word could be: \")\n",
    "    print (word[0][0])\n",
    "    print (\"Time taken for Good Turing Smoothing: \", time.time()-time1)\n",
    "    \n",
    "    #Kneser Ney Smoothing\n",
    "    wprob=defaultdict(dict)\n",
    "    time1=time.time()\n",
    "    wprob=kney(od3,od4)\n",
    "    word=wprob[test_tri]\n",
    "    word=sorted(word, key=lambda x: x[1], reverse=True)\n",
    "    print (\"After Kneser Ney Smoothing, the most probable word could be: \")\n",
    "    print (word[0][0])\n",
    "    print (\"Time taken for Kneser Ney Smoothing: \", time.time()-time1)\n",
    "    \n",
    "    \n",
    "    #Perplexity\n",
    "    time1=time.time()\n",
    "    quadperp(tokenList2,smooth_quad,smooth_tri,quadgramSet2)\n",
    "    print (\"Time taken to compute perplexity: \", time.time()-time1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your test string: I could not\n",
      "The next word could be: \n",
      "have\n",
      "Time taken for prediction:  0.42975807189941406\n",
      "After interpolation, the most probable word could be: \n",
      "be\n",
      "Time taken for prediction:  1.1564977169036865\n",
      "Score of the language model is: \n",
      "549\n",
      "Time taken for calculating Score:  11.998002529144287\n",
      "We will perform Add k smoothing now. Enter value of k: 3\n",
      "Time taken for Add k Smoothing:  35.680823802948\n",
      "After Good Turing Smoothing, the most probable word could be: \n",
      "conclude\n",
      "Time taken for Good Turing Smoothing:  0.08685827255249023\n",
      "After Kneser Ney Smoothing, the most probable word could be: \n",
      "walk\n",
      "Time taken for Kneser Ney Smoothing:  1.0913989543914795\n",
      "Quadgram Perplexity = 1.052211\n",
      "Time taken to compute perplexity:  0.017824411392211914\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
